{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set paths and file names\n",
    "path_raw = \"data/raw/TRTH/equities/US/\"\n",
    "path_clean = \"data/clean/TRTH/equities/US/\"\n",
    "\n",
    "# List of the files\n",
    "allfiles_trade=glob.glob(os.path.join(path_raw,\"trade/AAPL.OQ/*\"))\n",
    "allfiles_bbo=glob.glob(os.path.join(path_raw,\"bbo/AAPL.OQ/*\"))\n",
    "\n",
    "# Only keeps the 5 first to begin with\n",
    "allfiles_trade=np.sort(allfiles_trade)[:5]\n",
    "allfiles_bbo=np.sort(allfiles_bbo)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions \n",
    "def type_is_not_None(obj):\n",
    "    if type(obj) is type(None) : return False\n",
    "    return True\n",
    "\n",
    "\n",
    "### Functions that can be used with parallel computing\n",
    "import dask\n",
    "dask.config.set(scheduler=\"processes\")\n",
    "\n",
    "@dask.delayed\n",
    "def load_TRTH_trade(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             only_non_special_trades=True,\n",
    "             only_regular_trading_hours=True,\n",
    "             open_time=\"09:30:00\",\n",
    "             close_time=\"16:00:00\",\n",
    "             merge_sub_trades=True):\n",
    "    \n",
    "    DF = pd.read_csv(filename)\n",
    "    if (DF.empty == True) : return None\n",
    "\n",
    "    if only_non_special_trades:\n",
    "        DF = DF[DF[\"trade-stringflag\"]==\"uncategorized\"]\n",
    "\n",
    "    DF.drop(columns=[\"trade-rawflag\",\"trade-stringflag\"],axis=1,inplace=True)\n",
    "    \n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"D\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    \n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(open_time,close_time)    # warning: ever heard e.g. about Thanksgivings?\n",
    "    \n",
    "    if merge_sub_trades:\n",
    "           DF=DF.groupby(DF.index).agg(trade_price=pd.NamedAgg(column='trade-price', aggfunc='mean'),\n",
    "                                       trade_volume=pd.NamedAgg(column='trade-volume', aggfunc='sum'))\n",
    "    \n",
    "    return DF\n",
    "\n",
    "@dask.delayed\n",
    "def load_TRTH_bbo(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             open_time=\"09:30:00\",\n",
    "             close_time=\"16:00:00\",\n",
    "             only_regular_trading_hours=True):\n",
    "    \n",
    "    DF = pd.read_csv(filename)\n",
    "    if (DF.empty == True) : return None\n",
    "\n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"D\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    \n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(open_time,close_time)    # warning: ever heard e.g. about Thanksgivings?\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Load/treat/regroup/save the DF\n",
    "\n",
    "# Load the TRTH data\n",
    "allpromises_trade=[load_TRTH_trade(fn) for fn in allfiles_trade]\n",
    "allpromises_bbo=[load_TRTH_bbo(fn) for fn in allfiles_bbo]\n",
    "\n",
    "# Compute with dask\n",
    "alltrades=dask.compute(allpromises_trade)[0]            \n",
    "allbbos=dask.compute(allpromises_bbo)[0]    \n",
    "\n",
    "# Remove the None from the empty DF\n",
    "alltrades = list(filter(type_is_not_None,alltrades))\n",
    "allbbos = list(filter(type_is_not_None,allbbos))\n",
    "\n",
    "# Regroup the DF\n",
    "alltrades=pd.concat(alltrades)\n",
    "allbbos=pd.concat(allbbos)\n",
    "\n",
    "# Join them together\n",
    "allevents=alltrades.join(allbbos,how='inner')\n",
    "\n",
    "# Fill the DF\n",
    "allevents.ffill(inplace=True)\n",
    "\n",
    "# Save the cleaned DF\n",
    "if (not os.path.exists(path_clean)):\n",
    "    os.makedirs(path_clean)\n",
    "allevents.to_csv(os.path.join(path_clean,\"AAPL.OQ.csv.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
