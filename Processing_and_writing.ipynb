{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from multiprocessing import Pool\n",
    "from ipynb.fs.defs.Functions_multiprocessing import *\n",
    "# Need to have your functions in another .ipynb in order to use\n",
    "# multiprocessing with jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trading_days = 21\n",
    "#path = \"/Users/bkuznets/FBD_project/data/data/extraction/TRTH/raw/equities/US\"\n",
    "path_raw = \"data/raw/TRTH/equities/US\"\n",
    "path_clean = \"data/clean/TRTH/equities/US\"\n",
    "\n",
    "\n",
    "def load_trade(filename,\n",
    "               tz_exchange=\"America/New_York\",\n",
    "               only_non_special_trades=True,\n",
    "               only_regular_trading_hours=True,\n",
    "               open_time=\"09:30:00\",\n",
    "               close_time=\"16:00:00\",\n",
    "               merge_sub_trades=True):\n",
    "    DF = pd.read_csv(filename)\n",
    "    if DF.empty:\n",
    "        return None\n",
    "    if only_non_special_trades:\n",
    "        DF = DF[DF[\"trade-stringflag\"] == \"uncategorized\"]\n",
    "    DF.drop(columns=[\"trade-rawflag\", \"trade-stringflag\"], axis=1, inplace=True)\n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"], unit=\"D\", origin=\"1899-12-30\", utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)\n",
    "    DF.drop(columns=\"xltime\", inplace=True)\n",
    "    if only_regular_trading_hours:\n",
    "        DF = DF.between_time(open_time, close_time)\n",
    "    if merge_sub_trades:\n",
    "        DF = DF.groupby(DF.index).agg(trade_price=pd.NamedAgg(column='trade-price', aggfunc='mean'),\n",
    "                                      trade_volume=pd.NamedAgg(column='trade-volume', aggfunc='sum'))\n",
    "    return DF\n",
    "\n",
    "\n",
    "def load_bbo(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             open_time=\"09:30:00\",\n",
    "             close_time=\"16:00:00\",\n",
    "             only_regular_trading_hours=True):\n",
    "    DF = pd.read_csv(filename)\n",
    "    if DF.empty:\n",
    "        return None\n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"], unit=\"D\", origin=\"1899-12-30\", utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)\n",
    "    DF.drop(columns=\"xltime\", inplace=True)\n",
    "    if only_regular_trading_hours:\n",
    "        DF = DF.between_time(open_time, close_time)\n",
    "    return DF\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def load_trade_dask(filename):\n",
    "    DF = load_trade(filename)\n",
    "    return DF\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def load_bbo_dask(filename):\n",
    "    DF = load_bbo(filename)\n",
    "    return DF\n",
    "\n",
    "\n",
    "def type_is_not_None(obj):\n",
    "    if type(obj) is type(None):\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles_trade = glob.glob(os.path.join(path_raw, \"trade/AAPL.OQ/*\"))\n",
    "allfiles_bbo = glob.glob(os.path.join(path_raw, \"bbo/AAPL.OQ/*\"))\n",
    "allfiles_trade = np.sort(allfiles_trade)[:number_of_trading_days]\n",
    "allfiles_bbo = np.sort(allfiles_bbo)[:number_of_trading_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "df_trade = pd.DataFrame()\n",
    "for fn in allfiles_trade:\n",
    "    alltrades = load_trade(fn)\n",
    "    if type_is_not_None(alltrades):\n",
    "        df_trade = df_trade.append(alltrades)\n",
    "df_bbo = pd.DataFrame()\n",
    "for fn in allfiles_bbo:\n",
    "    allbbos = load_bbo(fn)\n",
    "    if type_is_not_None(allbbos):\n",
    "        df_bbo = df_bbo.append(allbbos)\n",
    "allevents = df_trade.join(df_bbo, how='inner')\n",
    "allevents.ffill(inplace=True)\n",
    "t1 = time.time()\n",
    "preprocessing_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "df_trade = pd.DataFrame()\n",
    "df_bbo = pd.DataFrame()\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(os.cpu_count())\n",
    "    alltrades_multi = pool.map(load_trade_multiprocessing, allfiles_trade)\n",
    "    allbbos_multi = pool.map(load_bbo_multiprocessing, allfiles_bbo)\n",
    "    alltrades_multi = list(filter(type_is_not_None, alltrades_multi))\n",
    "    df_trade = df_trade.append(alltrades_multi)\n",
    "    allbbos_multi = list(filter(type_is_not_None, allbbos_multi))\n",
    "    df_bbo = df_bbo.append(allbbos_multi)\n",
    "    allevents_multi = df_trade.join(df_bbo, how='inner')\n",
    "    allevents_multi.ffill(inplace=True)\n",
    "t1 = time.time()\n",
    "multiprocessing_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "df_trade = pd.DataFrame()\n",
    "df_bbo = pd.DataFrame()\n",
    "if __name__ == '__main__':\n",
    "    allpromises_trade = [load_trade_dask(fn) for fn in allfiles_trade]\n",
    "    allpromises_bbo = [load_bbo_dask(fn) for fn in allfiles_bbo]\n",
    "    alltrades_dask = dask.compute(allpromises_trade)[0]\n",
    "    allbbos_dask = dask.compute(allpromises_bbo)[0]\n",
    "    alltrades_dask = list(filter(type_is_not_None, alltrades_dask))\n",
    "    allbbos_dask = list(filter(type_is_not_None, allbbos_dask))\n",
    "    df_trade = df_trade.append(alltrades_dask)\n",
    "    df_bbo = df_bbo.append(allbbos_dask)\n",
    "    allevents_dask = df_trade.join(df_bbo, how='inner')\n",
    "    allevents_dask.ffill(inplace=True)\n",
    "t1 = time.time()\n",
    "dask_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "allevents.to_csv(os.path.join(path_clean, \"AAPL.OQ.csv.gz\"), compression='gzip')\n",
    "t1 = time.time()\n",
    "write_to_csvgz_time = t1 - t0\n",
    "\n",
    "t0 = time.time()\n",
    "allevents.to_parquet(os.path.join(path_clean, \"AAPL.OQ.parquet\"), index=False)\n",
    "t1 = time.time()\n",
    "write_to_parquet_time = t1 - t0\n",
    "\n",
    "t0 = time.time()\n",
    "allevents.to_hdf(os.path.join(path_clean, \"AAPL.OQ.h5\"), key='allevents')\n",
    "t1 = time.time()\n",
    "write_to_hdf5_time = t1 - t0\n",
    "\n",
    "t0 = time.time()\n",
    "table = pa.Table.from_pandas(allevents, preserve_index=False)\n",
    "pq.write_table(table, os.path.join(path_clean, \"AAPL.OQ.parquet\"))\n",
    "t1 = time.time()\n",
    "write_to_parquet_via_pyarrow_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time, straightforward computation... 75.0322961807251 s\n",
      "Processing time, multiprocessing, all cores... 37.251538038253784 s\n",
      "Processing time, dask... 61.591961145401 s\n",
      "Writing time, csv.gz... 39.933146953582764 s\n",
      "Writing time, parquet... 0.34884214401245117 s\n",
      "Writing time, hdf5... 0.6933450698852539 s\n",
      "Writing time, parquet via pyarrow... 0.36023807525634766 s\n"
     ]
    }
   ],
   "source": [
    "print('Processing time, straightforward computation...', preprocessing_time, 's')\n",
    "print('Processing time, multiprocessing, all cores...', multiprocessing_time, 's')\n",
    "print('Processing time, dask...', dask_time, 's')\n",
    "print('Writing time, csv.gz...', write_to_csvgz_time, 's')\n",
    "print('Writing time, parquet...', write_to_parquet_time, 's')\n",
    "print('Writing time, hdf5...', write_to_hdf5_time, 's')\n",
    "print('Writing time, parquet via pyarrow...', write_to_parquet_via_pyarrow_time, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
